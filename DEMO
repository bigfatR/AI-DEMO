import os
from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader
from llama_index.llms.dashscope import DashScope
from llama_index.embeddings.dashscope import DashScopeEmbedding
import dashscope
key = KEY
Settings.embed_model = DashScopeEmbedding(model_name= "text-embedding-v4", api_key = key)
Settings.llm = DashScope(model="deepseek-r1",
                         api_key= key)

# 构建索引
documents = SimpleDirectoryReader("data").load_data()
print(documents[0].text[:100])
from llama_index.core.node_parser import SentenceSplitter
parser = SentenceSplitter(chunk_size=512)
nodes = parser.get_nodes_from_documents(documents)
print("节点数:", len(nodes))  # 确认文档分块正常:ml-citation{ref="4" data="citationList"}

# 显式启用嵌入计算
# 替换原有索引构建代码
try:
    index = VectorStoreIndex.from_documents(
        documents,
        embed_model=Settings.embed_model,
        transformations=[
            SentenceSplitter(chunk_size=512),
            Settings.embed_model  # 显式声明嵌入步骤
        ]
    )
except Exception as e:
    print(f"API调用失败: {str(e)}")
    # 降级处理：使用本地缓存或简化模型

# 检查嵌入模型是否绑定成功
print(f"当前嵌入模型: {index._embed_model}")  # 应显示DashScopeEmbedding实例

# 检查节点处理状态
nodes = index.docstore.get_nodes(list(index.docstore.docs.keys()))
if nodes and nodes[0].embedding is None:
    print("警告: 需手动触发嵌入计算")
    x= index._embed_model.get_text_embedding(nodes[0].text)  # 测试单节点计算
    print(x)


# 查询示例
# query_engine = index.as_query_engine()
# response = query_engine.query("判断这是什么内容")
# print(response)